{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sys\n",
    "from glob import glob \n",
    "import json\n",
    "import gzip\n",
    "from tqdm import tqdm \n",
    "from pickle import dump\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sys.path.append('/Users/jerald/Documents/GaTechOMSA/CAPSTONE/repo')\n",
    "files = 'models/data/*.gz'\n",
    "\n",
    "class util(object):\n",
    "    def __init__(self, files):\n",
    "        files = glob(files)\n",
    "        self.file_names = sorted([f.split('/')[-1].split('.')[0] for f in files])\n",
    "        self.file_path_dict = {x:y for x,y in zip(self.file_names, files)}\n",
    "        self.name_map = {i:j for i, j in enumerate(self.file_names)}\n",
    "        print(f\"Data Files: {len(self.file_names)}\")\n",
    "        self.RandomState = 28\n",
    "        \n",
    "    def load(self, num):\n",
    "        file = self.file_path_dict[self.name_map[num]]\n",
    "        with gzip.open(file, 'rb') as f:\n",
    "            data = pd.read_csv(f, index_col=0)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Files: 43\n"
     ]
    }
   ],
   "source": [
    "class setup(util):\n",
    "    def __init__(self, files):\n",
    "        super().__init__(files)\n",
    "        \n",
    "    def _get_data(self, num=0):\n",
    "        self.df = self.load(num)\n",
    "        self.X = self.df.drop('FaultCode', axis=1)\n",
    "        self.feature_names = self.X.columns\n",
    "        self.y = self.df['FaultCode'].apply(lambda x: 0 if x == 0 else 1)\n",
    "        \n",
    "    def _split(self, X, y, size = .20):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=size)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "                \n",
    "    def _pca(self, X):\n",
    "        sc = StandardScaler()\n",
    "        self.pca = KernelPCA(kernel = 'rbf',random_state=self.RandomState, n_jobs=-1)\n",
    "        X = self.pca.fit_transform(sc.fit_transform(X))\n",
    "        self.ev = self.pca.explained_variance_ratio_[:5]\n",
    "        #print(f\"Explained Variance: {self.pca.explained_variance_ratio_[:4]}\")\n",
    "        return X\n",
    "\n",
    "    def _save_pca(self, num):\n",
    "        with open(f'models/decomp/{self.name_map[num]}.pkl', 'wb') as f:\n",
    "            dump(self.pca, f)\n",
    "\n",
    "data = setup(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Files: 43\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m     56\u001b[0m m \u001b[38;5;241m=\u001b[39m model(files)\n\u001b[0;32m---> 57\u001b[0m m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m0\u001b[39m, pc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m, in \u001b[0;36mmodel.run\u001b[0;34m(self, num, pc)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, num, pc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_init(num, pc)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_model()\n\u001b[1;32m     52\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_predictions()\n",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m, in \u001b[0;36mmodel.data_init\u001b[0;34m(self, num, pc)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pc:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecompose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pca(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_pca(num)        \n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_map[num]\n",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m, in \u001b[0;36msetup._pca\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     16\u001b[0m sc \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpca \u001b[38;5;241m=\u001b[39m KernelPCA(kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRandomState, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpca\u001b[38;5;241m.\u001b[39mfit_transform(sc\u001b[38;5;241m.\u001b[39mfit_transform(X))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpca\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_[:\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#print(f\"Explained Variance: {self.pca.explained_variance_ratio_[:4]}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/decomposition/_kernel_pca.py:469\u001b[0m, in \u001b[0;36mKernelPCA.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    449\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model from data in X and transform X.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# no need to use the kernel to transform X, use shortcut expression\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     X_transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigenvectors_ \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meigenvalues_)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/decomposition/_kernel_pca.py:436\u001b[0m, in \u001b[0;36mKernelPCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_centerer \u001b[38;5;241m=\u001b[39m KernelCenterer()\n\u001b[0;32m--> 436\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_kernel(X)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(K)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_inverse_transform:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# no need to use the kernel to transform X, use shortcut expression\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/decomposition/_kernel_pca.py:317\u001b[0m, in \u001b[0;36mKernelPCA._get_kernel\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdegree\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoef0\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0}\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pairwise_kernels(\n\u001b[1;32m    318\u001b[0m     X, Y, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel, filter_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    319\u001b[0m )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:2365\u001b[0m, in \u001b[0;36mpairwise_kernels\u001b[0;34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown kernel \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m metric)\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1770\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1768\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n\u001b[1;32m   1769\u001b[0m ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1770\u001b[0m Parallel(backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreading\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(\n\u001b[1;32m   1771\u001b[0m     fd(func, ret, s, X, Y[s], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m   1772\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m gen_even_slices(_num_samples(Y), effective_n_jobs(n_jobs))\n\u001b[1;32m   1773\u001b[0m )\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal for euclidean norm.\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m     \u001b[38;5;66;03m# TODO: do it also for other norms.\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m     np\u001b[38;5;241m.\u001b[39mfill_diagonal(ret, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/threading.py:634\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    632\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 634\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ml_env/lib/python3.12/threading.py:334\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    335\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class model(setup):\n",
    "    def __init__(self, files):\n",
    "        super().__init__(files)\n",
    "        self.decompose = False\n",
    "    \n",
    "    def data_init(self, num, pc = False):\n",
    "        self._get_data(num)\n",
    "        if pc:\n",
    "            self.decompose = True\n",
    "            self.X = self._pca(self.X)\n",
    "            self._save_pca(num)        \n",
    "        self.model_name = self.name_map[num]\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = self._split(self.X, self.y)\n",
    "\n",
    "    def save_iso(self):\n",
    "        outpath = f'models/reg/{self.model_name}.pkl'\n",
    "        \n",
    "        if self.decompose:\n",
    "            outpath = f'models/pca/{self.model_name}.pkl'\n",
    "        \n",
    "        with open(outpath, 'wb') as f:\n",
    "            dump(self.iso_model, f)\n",
    "                           \n",
    "    def _run_model(self):\n",
    "        \"\"\" Isolation Forest Model, need to cast the Y values to 1 and -1 \"\"\"\n",
    "        model = IsolationForest(random_state=self.RandomState)\n",
    "        params = {'contamination': [.2, .3,], 'bootstrap': [True, False]}\n",
    "        self.grid = GridSearchCV(model, params, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "        self.grid.fit(self.x_train, np.where(self.y_train == 0, 1, -1))\n",
    "        self.iso_model = self.grid.best_estimator_\n",
    "        self.save_iso()\n",
    "    \n",
    "    def _get_predictions(self):\n",
    "        \"\"\" Predictions, The predictions are casted to 0 and 1 \"\"\"\n",
    "        testing_prediction = np.where(self.iso_model.predict(self.x_test) == 1, 0, 1)\n",
    "        training_prediction = np.where(self.iso_model.predict(self.x_train) == 1, 0, 1)\n",
    "        results = pd.DataFrame({\n",
    "            'Testing Accuracy': accuracy_score(self.y_test, testing_prediction),\n",
    "            'Training Accuracy': accuracy_score(self.y_train, training_prediction),\n",
    "            'Testing AUC': roc_auc_score(self.y_test, testing_prediction),\n",
    "            'Training AUC': roc_auc_score(self.y_train, training_prediction)\n",
    "        }, index = [self.model_name])    \n",
    "        return results\n",
    "    \n",
    "    def run(self, num, pc=True):\n",
    "        self.data_init(num, pc)\n",
    "        self._run_model()\n",
    "        res = self._get_predictions()\n",
    "        return res\n",
    "\n",
    "\n",
    "m = model(files)\n",
    "m.run(0, pc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Files: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Progress: 100%|██████████| 43/43 [07:36<00:00, 10.62s/it]\n"
     ]
    }
   ],
   "source": [
    "class workflow(model):\n",
    "    def __init__(self, files):\n",
    "        super().__init__(files)\n",
    "        \n",
    "    def pca_workflow(self, num):\n",
    "        pred = self.run(num, pc=True) \n",
    "        return pred\n",
    "    \n",
    "    def reg_workflow(self, num):\n",
    "        pred = self.run(num, pc=False)\n",
    "        return pred\n",
    "\n",
    "    def main(self, decompose = True):\n",
    "        iter_list = list(self.name_map.keys())\n",
    "        results = pd.DataFrame()\n",
    "        for i in tqdm(iter_list, desc='Model Progress'):\n",
    "            if decompose == True:\n",
    "                res = self.pca_workflow(i)\n",
    "            else:\n",
    "                res = self.reg_workflow(i)\n",
    "            results = pd.concat([results, res])\n",
    "        return results\n",
    "    \n",
    "# PCA model \n",
    "w = workflow(files)\n",
    "pca_results = w.main(True)\n",
    "pca_results.round(4).to_csv('models/results/pca_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Model\n",
    "# w = workflow(files)\n",
    "# reg_results = w.main(False)\n",
    "# reg_results.round(4).to_csv('models/results/reg_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
